[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "CSHL Computational Genomics 2022",
    "section": "",
    "text": "Welcome to the course material from Stephanie Hicks at the CSHL Computational Genomics 2022 course!\n\n\n\nWorkshop material: https://stephaniehicks.com/cshlcg2022\nCode on GitHub: https://github.com/stephaniehicks/cshlcg2022\n\n\n\n\nStephanie C. Hicks, PhD\nAssociate Professor, Biostatistics, Johns Hopkins Bloomberg School of Public Health\nFaculty member, Johns Hopkins Data Science Lab\nPronouns: she/her \n\nweb: https://www.stephaniehicks.com\nemail: shicks19@jhu.edu\ntwitter: stephaniehicks\n\n\n\n\nThis course website was developed and is maintained by Stephanie C. Hicks.\nThe following individuals have contributed to improving the course or materials have been adapted from their courses:\nThe course materials are licensed under the GPL-3 License. Linked and embedded materials are governed by their own licenses. I assume that all external materials used or embedded here are covered under the educational fair use policy. If this is not the case and any material displayed here violates copyright, please let me know and I will remove it."
  },
  {
    "objectID": "intro-to-r.html",
    "href": "intro-to-r.html",
    "title": "1¬† Introduction to R",
    "section": "",
    "text": "There are only two kinds of languages: the ones people complain about and the ones nobody uses. ‚ÄîBjarne Stroustrup"
  },
  {
    "objectID": "intro-to-r.html#acknowledgements",
    "href": "intro-to-r.html#acknowledgements",
    "title": "1¬† Introduction to R",
    "section": "1.1 Acknowledgements",
    "text": "1.1 Acknowledgements\nMaterial for this chapter was borrowed and adopted from\n\nhttps://rdpeng.github.io/Biostat776/lecture-introduction-and-overview.html\nhttps://rafalab.github.io/dsbook\nhttps://rmd4sci.njtierney.com\nhttps://andreashandel.github.io/MADAcourse\n\n\n\n\n\n\n\nAdditional Resources\n\n\n\n\nAn overview and history of R from Roger Peng\nInstalling R and RStudio from Rafael Irizarry\nGetting Started in R and RStudio from Rafael Irizarry\nR for Data Science by Wickham & Grolemund (2017). Covers most of the basics of using R for data analysis.\nAdvanced R by Wickham (2014). Covers a number of areas including object-oriented, programming, functional programming, profiling and other advanced topics.\nRStudio IDE cheatsheet"
  },
  {
    "objectID": "intro-to-r.html#learning-objectives",
    "href": "intro-to-r.html#learning-objectives",
    "title": "1¬† Introduction to R",
    "section": "1.2 Learning objectives",
    "text": "1.2 Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nLearn about (some of) the history of R.\nIdentify some of the strengths and weaknesses of R.\nInstall R and Rstudio on your computer.\nKnow how to install and load R packages."
  },
  {
    "objectID": "intro-to-r.html#overview-and-history-of-r",
    "href": "intro-to-r.html#overview-and-history-of-r",
    "title": "1¬† Introduction to R",
    "section": "1.3 Overview and history of R",
    "text": "1.3 Overview and history of R\nBelow is a very quick introduction to R, to get you set up and running.\nLike every programming language, R has its advantages and disadvantages. If you search the internet, you will quickly discover lots of folks with opinions about R. Some of the features that are useful to know are:\n\nR is open-source, freely accessible, and cross-platform (multiple OS).\nR is a ‚Äúhigh-level‚Äù programming language, relatively easy to learn.\n\nWhile ‚ÄúLow-level‚Äù programming languages (e.g.¬†Fortran, C, etc) often have more efficient code, they can also be harder to learn because it is designed to be close to a machine language.\nIn contrast, high-level languages deal more with variables, objects, functions, loops, and other abstract CS concepts with a focus on usability over optimal program efficiency.\n\nR integrates easily with document preparation systems like LaTeX, but R files can also be used to create .docx, .pdf, .html, .ppt files with integrated R code output and graphics.\nThe R Community is very dynamic, helpful and welcoming.\n\nCheck out the #rstats or #rtistry on Twitter, TidyTuesday podcast and community activity in the R4DS Online Learning Community, and r/rstats subreddit.\nIf you are looking for more local resources, check out R-Ladies Baltimore.\n\nThrough R packages, it is easy to get lots of state-of-the-art algorithms.\nDocumentation and help files for R are generally good.\n\n\n1.3.1 Basic Features of R\nToday R runs on almost any standard computing platform and operating system.\nIts open source nature means that anyone is free to adapt the software to whatever platform they choose.\nOne nice feature that R shares with many popular open source projects is frequent releases. - These days there is a major annual release, typically in October, where major new features are incorporated and released to the public. - Throughout the year, smaller-scale bugfix releases will be made as needed.\nAnother key advantage that R has over many other packages (even today) is its sophisticated graphics capabilities. R‚Äôs ability to create ‚Äúpublication quality‚Äù graphics has existed since the very beginning and has generally been better than competing packages. Today, with many more visualization packages available than before, that trend continues.\nFinally, one of the joys of using R has nothing to do with the language itself, but rather with the active and vibrant user community. In many ways, a language is successful inasmuch as it creates a platform with which many people can create new things. R is that platform and thousands of people around the world have come together to make contributions to R, to develop packages, and help each other use R for all kinds of applications. The R-help and R-devel mailing lists have been highly active for over a decade now and there is considerable activity on web sites like Stack Overflow, Twitter #rstats, #rtistry, and Reddit.\n\n\n1.3.2 Free Software\nA major advantage that R has over many other statistical packages and is that it‚Äôs free in the sense of free software (it‚Äôs also free in the sense of free beer). The copyright for the primary source code for R is held by the R Foundation and is published under the GNU General Public License version 2.0.\nAccording to the Free Software Foundation, with free software, you are granted the following four freedoms\n\nThe freedom to run the program, for any purpose (freedom 0).\nThe freedom to study how the program works, and adapt it to your needs (freedom 1). Access to the source code is a precondition for this.\nThe freedom to redistribute copies so you can help your neighbor (freedom 2).\nThe freedom to improve the program, and release your improvements to the public, so that the whole community benefits (freedom 3). Access to the source code is a precondition for this.\n\n\n\n\n\n\n\nTip\n\n\n\nYou can visit the Free Software Foundation‚Äôs web site to learn a lot more about free software. The Free Software Foundation was founded by Richard Stallman in 1985 and Stallman‚Äôs personal web site is an interesting read if you happen to have some spare time.\n\n\n\n\n1.3.3 Design of the R System\nThe primary R system is available from the Comprehensive R Archive Network, also known as CRAN. CRAN also hosts many add-on packages that can be used to extend the functionality of R.\nThe R system is divided into 2 conceptual parts:\n\nThe ‚Äúbase‚Äù R system that you download from CRAN:\n\n\nLinux\nWindows\nMac\n\n\nEverything else.\n\nR functionality is divided into a number of packages.\n\nThe ‚Äúbase‚Äù R system contains, among other things, the base package which is required to run R and contains the most fundamental functions.\nThe other packages contained in the ‚Äúbase‚Äù system include utils, stats, datasets, graphics, grDevices, grid, methods, tools, parallel, compiler, splines, tcltk, stats4.\nThere are also ‚ÄúRecommended‚Äù packages: dplyr, ggplot2, etc.\n\nWhen you download a fresh installation of R from CRAN, you get all of the above, which represents a substantial amount of functionality. However, there are many other packages available:\n\nThere are over 10,000 packages on CRAN that have been developed by users and programmers around the world.\nThere are also many packages associated with the Bioconductor project.\nPeople often make packages available on their personal websites; there is no reliable way to keep track of how many packages are available in this fashion."
  },
  {
    "objectID": "intro-to-r.html#using-r-and-rstudio",
    "href": "intro-to-r.html#using-r-and-rstudio",
    "title": "1¬† Introduction to R",
    "section": "1.4 Using R and RStudio",
    "text": "1.4 Using R and RStudio\n\nIf R is the engine and bare bones of your car, then RStudio is like the rest of the car. The engine is super critical part of your car. But in order to make things properly functional, you need to have a steering wheel, comfy seats, a radio, rear and side view mirrors, storage, and seatbelts. ‚Äî Nicholas Tierney\n\n[Source]\nThe RStudio layout has the following features:\n\nOn the upper left, something called a Rmarkdown script\nOn the lower left, the R console\nOn the lower right, the view for files, plots, packages, help, and viewer.\nOn the upper right, the environment / history pane\n\n\n\n\nA screenshot of the RStudio integrated developer environment (IDE) ‚Äì aka the working environment\n\n\nThe R console is the bit where you can run your code. This is where the R code in your Rmarkdown document gets sent to run (we‚Äôll learn about these files later).\nThe file/plot/pkg viewer is a handy browser for your current files, like Finder, or File Explorer, plots are where your plots appear, you can view packages, see the help files. And the environment / history pane contains the list of things you have created, and the past commands that you have run.\n\n1.4.1 Installing R and RStudio\n\nIf you have not already, install R first. If you already have R installed, make sure it is a fairly recent version, version 4.0 or newer. If yours is older, I suggest you update (install a new R version).\nOnce you have R installed, install the free version of RStudio Desktop. Again, make sure it‚Äôs a recent version.\n\n\n\n\n\n\n\nTip\n\n\n\nInstalling R and RStudio should be fairly straightforward. However, a great set of detailed instructions is in Rafael Irizarry‚Äôs dsbook\n\nhttps://rafalab.github.io/dsbook/installing-r-rstudio.html\n\n\n\nI personally only have experience with Mac, but everything should work on all the standard operating systems (Windows, Mac, and even Linux).\n\n\n1.4.2 RStudio default options\nTo first get set up, I highly recommend changing the following setting\nTools > Global Options (or Cmd + , on macOS)\nUnder the General tab:\n\nFor workspace\n\nUncheck restore .RData into workspace at startup\nSave workspace to .RData on exit : ‚ÄúNever‚Äù\n\nFor History\n\nUncheck ‚ÄúAlways save history (even when not saving .RData)\nUncheck ‚ÄúRemove duplicate entries in history‚Äù\n\n\nThis means that you won‚Äôt save the objects and other things that you create in your R session and reload them. This is important for two reasons\n\nReproducibility: you don‚Äôt want to have objects from last week cluttering your session\nPrivacy: you don‚Äôt want to save private data or other things to your session. You only want to read these in.\n\nYour ‚Äúhistory‚Äù is the commands that you have entered into R.\nAdditionally, not saving your history means that you won‚Äôt be relying on things that you typed in the last session, which is a good habit to get into!\n\n\n1.4.3 Installing and loading R packages\nAs we discussed, most of the functionality and features in R come in the form of add-on packages. There are tens of thousands of packages available, some big, some small, some well documented, some not.\nThe ‚Äúofficial‚Äù place for packages is the CRAN website. If you are interested in packages on a specific topic, the CRAN task views provide curated descriptions of packages sorted by topic.\nTo install an R package from CRAN, one can simply call the install.packages() function and pass the name of the package as an argument. For example, to install the ggplot2 package from CRAN: open RStudio,go to the R prompt (the > symbol) in the lower-left corner and type\n\ninstall.packages(\"ggplot2\")\n\nand the appropriate version of the package will be installed.\nOften, a package needs other packages to work (called dependencies), and they are installed automatically. It usually does not matter if you use a single or double quotation mark around the name of the package.\n\n\n\n\n\n\nQuestions\n\n\n\n\nAs you installed the ggplot2 package, what other packages were installed?\nWhat happens if you tried to install GGplot2?\n\n\n\nIt could be that you already have all packages required by ggplot2 installed. In that case, you will not see any other packages installed. To see which of the packages above ggplot2 needs (and thus installs if it is not present), type into the R console:\n\ntools::package_dependencies(\"ggplot2\")\n\nIn RStudio, you can also install (and update/remove) packages by clicking on the ‚ÄòPackages‚Äô tab in the bottom right window.\nIt is very common these days for packages to be developed on GitHub. It is possible to install packages from GitHub directly. Those usually contain the latest version of the package, with features that might not be available yet on the CRAN website. Sometimes, in early development stages, a package is only on GitHub until the developer(s) feel it is good enough for CRAN submission. So installing from GitHub gives you the latest. The downside is that packages under development can often be buggy and not working right. To install packages from GitHub, you need to install the remotes package and then use the following function\n\nremotes::install_github()\n\nYou only need to install a package once, unless you upgrade/re-install R. Once installed, you still need to load the package before you can use it. That has to happen every time you start a new R session. You do that using the library() command. For instance to load the ggplot2 package, type\n\nlibrary('ggplot2')\n\nYou may or may not see a short message on the screen. Some packages show messages when you load them, and others do not.\nThis was a quick overview of R packages. We will use a lot of them, so you will get used to them rather quickly.\n\n\n1.4.4 Getting started in RStudio\nWhile one can use R and do pretty much every task, including all the ones we cover in this class, without using RStudio, RStudio is very useful, has lots of features that make your R coding life easier and has become pretty much the default integrated development environment (IDE) for R. Since RStudio has lots of features, it takes time to learn them. A good resource to learn more about RStudio are the R Studio Essentials collection of videos.\n\n\n\n\n\n\nTip\n\n\n\nFor more information on setting up and getting started with R, RStudio, and R packages, read the Getting Started chapter in the dsbook:\n\nhttps://rafalab.github.io/dsbook/getting-started.html\n\nThis chapter gives some tips, shortcuts, and ideas that might be of interest even to those of you who already have R and/or RStudio experience."
  },
  {
    "objectID": "intro-to-r.html#session-info",
    "href": "intro-to-r.html#session-info",
    "title": "1¬† Introduction to R",
    "section": "1.5 Session Info",
    "text": "1.5 Session Info\n\nsessionInfo()\n\nR version 4.2.2 (2022-10-31)\nPlatform: aarch64-apple-darwin21.6.0 (64-bit)\nRunning under: macOS Ventura 13.0.1\n\nMatrix products: default\nBLAS:   /opt/homebrew/Cellar/openblas/0.3.21/lib/libopenblasp-r0.3.21.dylib\nLAPACK: /opt/homebrew/Cellar/r/4.2.2/lib/R/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] digest_0.6.30     jsonlite_1.8.3    magrittr_2.0.3    evaluate_0.18    \n [5] rlang_1.0.6       stringi_1.7.8     cli_3.4.1         rstudioapi_0.14  \n [9] rmarkdown_2.18    tools_4.2.2       stringr_1.4.1     htmlwidgets_1.5.4\n[13] xfun_0.35         yaml_2.3.6        fastmap_1.1.0     compiler_4.2.2   \n[17] htmltools_0.5.3   knitr_1.41"
  },
  {
    "objectID": "exercises-01.html",
    "href": "exercises-01.html",
    "title": "Group work",
    "section": "",
    "text": "Let‚Äôs take 5 mins and pair up with another person. Pick out a few of the questions below to ask each other and try to answer them."
  },
  {
    "objectID": "exercises-01.html#r-and-rstudio",
    "href": "exercises-01.html#r-and-rstudio",
    "title": "Group work",
    "section": "R and RStudio",
    "text": "R and RStudio\n\nIf a software company asks you, as a requirement for using their software, to sign a license that restricts you from using their software to commit illegal activities, is this consistent with the ‚ÄúFour Freedoms‚Äù of Free Software?\nWhat is an R package and what is it used for?\nWhat function in R can be used to install packages from CRAN?\nWhat is a limitation of the current R system?\nHow many packages are on CRAN? Where can you find this information?\nHow many packages are on GitHub? Is it possible to find this information?"
  },
  {
    "objectID": "reproducible-res.html",
    "href": "reproducible-res.html",
    "title": "2¬† Reproducible Research",
    "section": "",
    "text": "An article about computational results is advertising, not scholarship. The actual scholarship is the full software environment, code and data, that produced the result. ‚ÄîClaerbout and Karrenbach (1992)\n[Link to Claerbout and Karrenbach (1992) article]"
  },
  {
    "objectID": "reproducible-res.html#acknowledgements",
    "href": "reproducible-res.html#acknowledgements",
    "title": "2¬† Reproducible Research",
    "section": "2.1 Acknowledgements",
    "text": "2.1 Acknowledgements\nMaterial for this chapter was borrowed and adopted from\n\nhttps://rdpeng.github.io/Biostat776/lecture-literate-statistical-programming.html\nhttps://statsandr.com/blog/tips-and-tricks-in-rstudio-and-r-markdown\nhttps://ropensci.github.io/reproducibility-guide/sections/introduction\nhttps://rdpeng.github.io/Biostat776\nReproducible Research: A Retrospective by Roger Peng and Stephanie Hicks\n\n\n\n\n\n\n\nAdditional Resources\n\n\n\n\nRMarkdown Tips and Tricks by Indrajeet Patil\nhttps://bookdown.org/yihui/rmarkdown\nhttps://bookdown.org/yihui/rmarkdown-cookbook"
  },
  {
    "objectID": "reproducible-res.html#learning-objectives",
    "href": "reproducible-res.html#learning-objectives",
    "title": "2¬† Reproducible Research",
    "section": "2.2 Learning objectives",
    "text": "2.2 Learning objectives\n\n\n\n\n\n\nLearning objectives\n\n\n\nAt the end of this lesson you will:\n\nKnow the difference between replication and reproducibility\nIdentify valid reasons why replication and/or reproducibility is not always possible\nIdentify key components to enable reproducible data analyses\nBe able to define literate programming\nRecognize differences between available tools to for literate programming\nKnow how to efficiently work within RStudio for efficient literate programming\nCreate a R Markdown document"
  },
  {
    "objectID": "reproducible-res.html#introduction",
    "href": "reproducible-res.html#introduction",
    "title": "2¬† Reproducible Research",
    "section": "2.3 Introduction",
    "text": "2.3 Introduction\nThis chapter will be about reproducible reporting, and I want to take the opportunity to cover some basic concepts and ideas that are related to reproducible reporting, just in case you have not heard about it or do not know what it is.\nBefore we get to reproducibility, we need to cover a little background with respect to how science works (even if you are not a scientist, this is important).\nThe ultimate standard in strengthening scientific evidence is replication. Assume you claim that X causes Y, or that Vitamin C improves disease. The goal of replication is to have independent people to do independent things with different data, different methods, and different laboratories and see if they get the same result.\nThere is a sense that if a relationship in nature is truly there, then it should be robust to having different people discover it in different ways. Replication is particularly important in areas where findings can have big policy impacts or can influence regulatory types of decisions.\n\n2.3.1 What is wrong with replication?\nThere is really nothing wrong with it. This is what science has been doing for a long time, through hundreds of years. And there is nothing wrong with it today.\nBut the problem is that it is becoming more and more challenging to do replication or to replicate other studies.\nHere are some reasons:\n\nOften times studies are much larger and more costly than previously. If you want to do ten versions of the same study, you need ten times as much money and there is not as much money around as there used to be.\nSometimes it is difficult to replicate a study because if the original study took 20 years to complete, it is difficult to wait around another 20 years for replication.\nSome studies are just plain unique, such as studying the impact of a massive earthquake in a very specific location and time. If you are looking at a unique situation in time or a unique population, you cannot readily replicate that situation.\n\nThere are a lot of good reasons why you cannot replicate a study. If you cannot replicate a study, is the alternative just to do nothing (?? üò±), just let that study stand by itself?\nThe idea behind a reproducible reporting is to create a kind of minimum standard (or a middle ground) where we will not be replicating a study, but maybe we can do something in between. What can we do that‚Äôs in between the gold standard and doing nothing?\nThat is where reproducibility comes in. That‚Äôs how we can kind of bridge the gap between replication and nothing.\nIn non-research settings, often full replication is not even the point. Often the goal is to preserve something to the point where anybody in an organization can repeat what you did (for example, after you leave the organization).\n\nIn this case, reproducibility is key to maintaining the history of a project and making sure that every step along the way is clear.\n\n\n\n\n\n\n\nSummary\n\n\n\n\nReplication, whereby scientific questions are examined and verified independently by different scientists, is the gold standard for scientific validity.\nReplication can be difficult and often there are no resources to independently replicate a study.\nReproducibility, whereby data and code are re-analyzed by independent scientists to obtain the same results of the original investigator, is a reasonable minimum standard when replication is not possible."
  },
  {
    "objectID": "reproducible-res.html#reproducibility-to-the-rescue",
    "href": "reproducible-res.html#reproducibility-to-the-rescue",
    "title": "2¬† Reproducible Research",
    "section": "2.4 Reproducibility to the Rescue",
    "text": "2.4 Reproducibility to the Rescue\nLet‚Äôs first define reproducibility. The basic idea is that you need to make the data available for the original study and the computational methods available so that other people can look at your data and run the kind of analysis that you have run, and come to the same findings that you found.\nWhat reproducible reporting is about is a validation of the data analysis (not the original question itself). Because you are not collecting independent data using independent methods, it is a little bit more difficult to validate the scientific question itself. But if you can take someone‚Äôs data and reproduce their findings, then you can, in some sense, validate the data analysis.\nIn this way, you can at least have confidence that you can reproduce the analysis.\nRecently, there has been a lot of discussion of reproducibility in the media and in the scientific literature. For example, he journal Science had a special issue on reproducibility and data replication.\n\nhttps://www.science.org/toc/science/334/6060\n\n\n2.4.1 Why does this matter?\nHere is an example. In 2012, a feature on the TV show 60 minutes looked at a major incident at Duke University where many results involving a promising cancer test were found to be not reproducible. This led to a number of studies and clinical trials having to be stopped, followed by an investigation which is still ongoing.\n\n\n\n\n[Source on YouTube]\n\n\n2.4.2 Types of reproducibility\nWhat are the different kinds of reproducible research? Enabling reproducibility can be complicated, but by separating out some of the levels and degrees of reproducibility the problem can become more manageable because we can focus our efforts on what best suits our specific scientific domain. Victoria Stodden (2014), a prominent scholar on this topic, has identified some useful distinctions in reproducible research:\n\nComputational reproducibility: when detailed information is provided about code, software, hardware and implementation details.\nEmpirical reproducibility: when detailed information is provided about non-computational empirical scientific experiments and observations. In practice this is enabled by making data freely available, as well as details of how the data was collected.\nStatistical reproducibility: when detailed information is provided about the choice of statistical tests, model parameters, threshold values, etc. This mostly relates to pre-registration of study design to prevent p-value hacking and other manipulations.\n\n[Source]\n\n\n2.4.3 Elements of computational reproducibility\nWhat do we need for computational reproducibility? There are a variety of ways to talk about this, but one basic definition that we hae come up with is that there are four things that are required to make results reproducible:\n\nAnalytic data. The data that were used for the analysis that was presented should be available for others to access. This is different from the raw data because very often in a data analysis the raw data are not all used for the analysis, but rather some subset is used. It may be interesting to see the raw data but impractical to actually have it. Analytic data is key to examining the data analysis.\nAnalytic code. The analytic code is the code that was applied to the analytic data to produce the key results. This may be preprocessing code, regression modeling code, or really any other code used to produce the results from the analytic data.\nDocumentation. Documentation of that code and the data is very important.\nDistribution. Finally, there needs to be some standard means of distribution, so all this data in the code is easily accessible.\n\n\n\n\n\n\n\nSummary\n\n\n\n\nReproducible reporting is about is a validation of the data analysis\nThere are multiple types of reproducibility\nThere are four elements to computational reproducibility"
  },
  {
    "objectID": "reproducible-res.html#x-to-computational-x",
    "href": "reproducible-res.html#x-to-computational-x",
    "title": "2¬† Reproducible Research",
    "section": "2.5 ‚ÄúX‚Äù to ‚ÄúComputational X‚Äù",
    "text": "2.5 ‚ÄúX‚Äù to ‚ÄúComputational X‚Äù\nWhat is driving this need for a ‚Äúreproducibility middle ground‚Äù between replication and doing nothing?\nFor starters, there are a lot of new technologies on the scene and in many different fields of study including, biology, chemistry and environmental science. These technologies allow us to collect data at a much higher throughput so we end up with these very complex and very high dimensional data sets.\nThese datasets can be collected almost instantaneously compared to even just ten years ago‚Äîthe technology has allowed us to create huge data sets at essentially the touch of a button. Furthermore, we the computing power to take existing (already huge) databases and merge them into even bigger and bigger databases. Finally, the massive increase in computing power has allowed us to implement more sophisticated and complex analysis routines.\nThe analyses themselves, the models that we fit and the algorithms that we run, are much much more complicated than they used to be. Having a basic understanding of these algorithms is difficult, even for a sophisticated person, and it is almost impossible to describe these algorithms with words alone.\nUnderstanding what someone did in a data analysis now requires looking at code and scrutinizing the computer programs that people used.\nThe bottom line with all these different trends is that for every field ‚ÄúX‚Äù, there is now ‚ÄúComputational X‚Äù. There‚Äôs computational biology, computational astronomy‚Äîwhatever it is you want, there is a computational version of it."
  },
  {
    "objectID": "reproducible-res.html#literate-programming",
    "href": "reproducible-res.html#literate-programming",
    "title": "2¬† Reproducible Research",
    "section": "2.6 Literate programming",
    "text": "2.6 Literate programming\nOne basic idea to make writing reproducible reports easier is what‚Äôs known as literate statistical programming (or sometimes called literate statistical practice). This comes from the idea of literate programming in the area of writing computer programs.\nThe idea is to think of a report or a publication as a stream of text and code.\n\nThe text is readable by people and the code is readable by computers.\nThe analysis is described in a series of text and code chunks.\nEach kind of code chunk will do something like load some data or compute some results.\nEach text chunk will relay something in a human readable language.\n\nThere might also be presentation code that formats tables and figures and there‚Äôs article text that explains what‚Äôs going on around all this code. This stream of text and code is a literate statistical program or a literate statistical analysis.\n\n2.6.1 Weaving and Tangling\nLiterate programs by themselves are a bit difficult to work with, but they can be processed in two important ways.\nLiterate programs can be weaved to produce human readable documents like PDFs or HTML web pages, and they can tangled to produce machine-readable ‚Äúdocuments‚Äù, or in other words, machine readable code.\nThe basic idea behind literate programming in order to generate the different kinds of output you might need, you only need a single source document‚Äîyou can weave and tangle to get the rest.\nIn order to use a system like this you need a documentational language, that‚Äôs human readable, and you need a programming language that‚Äôs machine readable (or can be compiled/interpreted into something that‚Äôs machine readable).\n\n\n2.6.2 rmarkdown\nA common choice for literate programming with R code is to build documents based on Markdown language. A markdown file is a plain text file that is typically given the extension .md.. The rmarkdown R package takes a R Markdown file (.Rmd) and weaves together R code chunks like this:\n```{r plot1, height=4, width=5, eval=FALSE, echo=TRUE}\ndata(airquality)\nplot(airquality$Ozone ~ airquality$Wind)\n```\n\n\n\n\n\n\nTip\n\n\n\nThe best resource for learning about R Markdown this by Yihui Xie, J. J. Allaire, and Garrett Grolemund:\n\nhttps://bookdown.org/yihui/rmarkdown\n\nThe R Markdown Cookbook by Yihui Xie, Christophe Dervieux, and Emily Riederer is really good too:\n\nhttps://bookdown.org/yihui/rmarkdown-cookbook\n\nThe authors of the 2nd book describe the motivation for the 2nd book as:\n\n‚ÄúHowever, we have received comments from our readers and publisher that it would be beneficial to provide more practical and relatively short examples to show the interesting and useful usage of R Markdown, because it can be daunting to find out how to achieve a certain task from the aforementioned reference book (put another way, that book is too dry to read). As a result, this cookbook was born.‚Äù\n\n\n\nBecause this is chapter is built in a .qmd file (which is very similar to a .Rmd file), let‚Äôs demonstrate how this work. I am going to change eval=FALSE to eval=TRUE.\n\ndata(airquality)\nplot(airquality$Ozone ~ airquality$Wind)\n\n\n\n\n\n\n\n\n\n\nQuestions\n\n\n\n\nWhy do we not see the back ticks ``` anymore in the code chunk above that made the plot?\nWhat do you think we should do if we want to have the code executed, but we want to hide the code that made it?\n\n\n\nBefore we leave this section, I find that there is quite a bit of terminology to understand the magic behind rmarkdown that can be confusing, so let‚Äôs break it down:\n\nPandoc. Pandoc is a command line tool with no GUI that converts documents (e.g.¬†from number of different markup formats to many other formats, such as .doc, .pdf etc). It is completely independent from R (but does come bundled with RStudio).\nMarkdown (markup language). Markdown is a lightweight markup language with plain text formatting syntax designed so that it can be converted to HTML and many other formats. A markdown file is a plain text file that is typically given the extension .md. It is completely independent from R.\nmarkdown (R package). markdown is an R package which converts .md files into HTML. It is no longer recommended for use has been surpassed by rmarkdown (discussed below).\nR Markdown (markup language). R Markdown is an extension of the markdown syntax. R Markdown files are plain text files that typically have the file extension .Rmd.\nrmarkdown (R package). The R package rmarkdown is a library that uses pandoc to process and convert .Rmd files into a number of different formats. This core function is rmarkdown::render(). Note: this package only deals with the markdown language. If the input file is e.g.¬†.Rhtml or .Rnw, then you need to use knitr prior to calling pandoc (see below).\n\n\n\n\n\n\n\nTip\n\n\n\nCheck out the R Markdown Quick Tour for more:\n\nhttps://rmarkdown.rstudio.com/authoring_quick_tour.html\n\n\n\n\n\n\nArtwork by Allison Horst on RMarkdown\n\n\n\n\n2.6.3 knitr\nOne of the alternative that has come up in recent times is something called knitr.\n\nThe knitr package for R takes a lot of these ideas of literate programming and updates and improves upon them.\nknitr still uses R as its programming language, but it allows you to mix other programming languages in.\nYou can also use a variety of documentation languages now, such as LaTeX, markdown and HTML.\nknitr was developed by Yihui Xie while he was a graduate student at Iowa State and it has become a very popular package for writing literate statistical programs.\n\nKnitr takes a plain text document with embedded code, executes the code and ‚Äòknits‚Äô the results back into the document.\nFor for example, it converts\n\nAn R Markdown (.Rmd) file into a standard markdown file (.md)\nAn .Rnw (Sweave) file into to .tex format.\nAn .Rhtml file into to .html.\n\nThe core function is knitr::knit() and by default this will look at the input document and try and guess what type it is e.g.¬†Rnw, Rmd etc.\nThis core function performs three roles:\n\nA source parser, which looks at the input document and detects which parts are code that the user wants to be evaluated.\nA code evaluator, which evaluates this code\nAn output renderer, which writes the results of evaluation back to the document in a format which is interpretable by the raw output type. For instance, if the input file is an .Rmd, the output render marks up the output of code evaluation in .md format.\n\n\n\n\n\n\nConverting a Rmd file to many outputs using knitr and pandoc\n\n\n\n\n[Source]\nAs seen in the figure above, from there pandoc is used to convert e.g.¬†a .md file into many other types of file formats into a .html, etc.\nSo in summary:\n\n‚ÄúR Markdown stands on the shoulders of knitr and Pandoc. The former executes the computer code embedded in Markdown, and converts R Markdown to Markdown. The latter renders Markdown to the output format you want (such as PDF, HTML, Word, and so on).‚Äù\n\n[Source]"
  },
  {
    "objectID": "reproducible-res.html#create-and-knit-your-first-r-markdown-document",
    "href": "reproducible-res.html#create-and-knit-your-first-r-markdown-document",
    "title": "2¬† Reproducible Research",
    "section": "2.7 Create and Knit Your First R Markdown Document",
    "text": "2.7 Create and Knit Your First R Markdown Document\n\n\nWhen creating your first R Markdown document, in RStudio you can\n\nGo to File > New File > R Markdown‚Ä¶\nFeel free to edit the Title\nMake sure to select ‚ÄúDefault Output Format‚Äù to be HTML\nClick ‚ÄúOK‚Äù. RStudio creates the R Markdown document and places some boilerplate text in there just so you can see how things are setup.\nClick the ‚ÄúKnit‚Äù button (or go to File > Knit Document) to make sure you can create the HTML output\n\nIf you successfully knit your first R Markdown document, then congratulations!\n\n\n\n\n\nMission accomplished!"
  },
  {
    "objectID": "reproducible-res.html#tips-and-tricks-in-r-markdown-in-rstudio",
    "href": "reproducible-res.html#tips-and-tricks-in-r-markdown-in-rstudio",
    "title": "2¬† Reproducible Research",
    "section": "2.8 Tips and tricks in R Markdown in RStudio",
    "text": "2.8 Tips and tricks in R Markdown in RStudio\nHere are shortcuts and tips on efficiently using RStudio to improve how you write code.\n\n2.8.1 Run code\nIf you want to run a code chunk:\ncommand + Enter on Mac\nCtrl + Enter on Windows\n\n\n2.8.2 Insert a comment in R and R Markdown\nTo insert a comment:\ncommand + Shift + C on Mac\nCtrl + Shift + C on Windows\nThis shortcut can be used both for:\n\nR code when you want to comment your code. It will add a # at the beginning of the line\nfor text in R Markdown. It will add <!-- and --> around the text\n\nNote that if you want to comment more than one line, select all the lines you want to comment then use the shortcut. If you want to uncomment a comment, apply the same shortcut.\n\n\n2.8.3 Knit a R Markdown document\nYou can knit R Markdown documents by using this shortcut:\ncommand + Shift + K on Mac\nCtrl + Shift + K on Windows\n\n\n2.8.4 Code snippets\nCode snippets is usually a few characters long and is used as a shortcut to insert a common piece of code. You simply type a few characters then press Tab and it will complete your code with a larger code. Tab is then used again to navigate through the code where customization is required. For instance, if you type fun then press Tab, it will auto-complete the code with the required code to create a function:\nname <- function(variables) {\n  \n}\nPressing Tab again will jump through the placeholders for you to edit it. So you can first edit the name of the function, then the variables and finally the code inside the function (try by yourself!).\nThere are many code snippets by default in RStudio. Here are the code snippets I use most often:\n\nlib to call library()\n\n\nlibrary(package)\n\n\nmat to create a matrix\n\n\nmatrix(data, nrow = rows, ncol = cols)\n\n\nif, el, and ei to create conditional expressions such as if() {}, else {} and else if () {}\n\n\nif (condition) {\n  \n}\n\nelse {\n  \n}\n\nelse if (condition) {\n  \n}\n\n\nfun to create a function\n\n\nname <- function(variables) {\n  \n}\n\n\nfor to create for loops\n\n\nfor (variable in vector) {\n  \n}\n\n\nts to insert a comment with the current date and time (useful if you have very long code and share it with others so they see when it has been edited)\n\n\n# Tue Jan 21 20:20:14 2020 ------------------------------\n\nYou can see all default code snippets and add yours by clicking on Tools > Global Options‚Ä¶ > Code (left sidebar) > Edit Snippets‚Ä¶\n\n\n2.8.5 Ordered list in R Markdown\nIn R Markdown, when creating an ordered list such as this one:\n\nItem 1\nItem 2\nItem 3\n\nInstead of bothering with the numbers and typing\n1. Item 1\n2. Item 2\n3. Item 3\nyou can simply type\n1. Item 1\n1. Item 2\n1. Item 3\nfor the exact same result (try it yourself or check the code of this article!). This way you do not need to bother which number is next when creating a new item.\nTo go even further, any numeric will actually render the same result as long as the first item is the number you want to start from. For example, you could type:\n1. Item 1\n7. Item 2\n3. Item 3\nwhich renders\n\nItem 1\nItem 2\nItem 3\n\nHowever, I suggest always using the number you want to start from for all items because if you move one item at the top, the list will start with this new number. For instance, if we move 7. Item 2 from the previous list at the top, the list becomes:\n7. Item 2\n1. Item 1\n3. Item 3\nwhich incorrectly renders\n\nItem 2\nItem 1\nItem 3\n\n\n\n2.8.6 New code chunk in R Markdown\nWhen editing R Markdown documents, you will need to insert a new R code chunk many times. The following shortcuts will make your life easier:\ncommand + option + I on Mac (or command + alt + I depending on your keyboard)\nCtrl + ALT + I on Windows\n\n\n2.8.7 Reformat code\nA clear and readable code is always easier and faster to read (and look more professional when sharing it to collaborators). To automatically apply the most common coding guidelines such as white spaces, indents, etc., use:\ncmd + Shift + A on Mac\nCtrl + Shift + A on Windows\nSo for example the following code which does not respect the guidelines (and which is not easy to read):\n1+1\n  for(i in 1:10){if(!i%%2){next}\nprint(i)\n }\nbecomes much more neat and readable:\n1 + 1\nfor (i in 1:10) {\n  if (!i %% 2) {\n    next\n  }\n  print(i)\n}\n\n\n2.8.8 RStudio addins\nRStudio addins are extensions which provide a simple mechanism for executing advanced R functions from within RStudio. In simpler words, when executing an addin (by clicking a button in the Addins menu), the corresponding code is executed without you having to write the code. RStudio addins have the advantage that they allow you to execute complex and advanced code much more easily than if you would have to write it yourself.\n\n\n\n\n\n\nTip\n\n\n\nFor more information about RStudio addins, check out:\n\nhttps://rstudio.github.io/rstudioaddins\nhttps://statsandr.com/blog/tips-and-tricks-in-rstudio-and-r-markdown\n\n\n\n\n\n2.8.9 Others\nSimilar to many other programs, you can also use:\n\ncommand + Shift + N on Mac and Ctrl + Shift + N on Windows to open a new R Script\ncommand + S on Mac and Ctrl + S on Windows to save your current script or R Markdown document\n\nCheck out Tools ‚Äì> Keyboard Shortcuts Help to see a long list of these shortcuts."
  },
  {
    "objectID": "reproducible-res.html#session-info",
    "href": "reproducible-res.html#session-info",
    "title": "2¬† Reproducible Research",
    "section": "2.9 Session Info",
    "text": "2.9 Session Info\n\nsessionInfo()\n\nR version 4.2.2 (2022-10-31)\nPlatform: aarch64-apple-darwin21.6.0 (64-bit)\nRunning under: macOS Ventura 13.0.1\n\nMatrix products: default\nBLAS:   /opt/homebrew/Cellar/openblas/0.3.21/lib/libopenblasp-r0.3.21.dylib\nLAPACK: /opt/homebrew/Cellar/r/4.2.2/lib/R/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] compiler_4.2.2    pillar_1.8.1      sysfonts_0.8.8    tools_4.2.2      \n [5] digest_0.6.30     jsonlite_1.8.3    evaluate_0.18     lifecycle_1.0.3  \n [9] tibble_3.1.8      gtable_0.3.1      pkgconfig_2.0.3   rlang_1.0.6      \n[13] cli_3.4.1         DBI_1.1.3         rstudioapi_0.14   yaml_2.3.6       \n[17] xfun_0.35         proto_1.0.0       fastmap_1.1.0     showtextdb_3.0   \n[21] stringr_1.4.1     dplyr_1.0.10      knitr_1.41        generics_0.1.3   \n[25] vctrs_0.5.1       htmlwidgets_1.5.4 grid_4.2.2        emojifont_0.5.5  \n[29] tidyselect_1.2.0  glue_1.6.2        R6_2.5.1          fansi_1.0.3      \n[33] rmarkdown_2.18    ggplot2_3.4.0     magrittr_2.0.3    scales_1.2.1     \n[37] htmltools_0.5.3   showtext_0.9-5    assertthat_0.2.1  colorspace_2.0-3 \n[41] utf8_1.2.2        stringi_1.7.8     munsell_0.5.0"
  },
  {
    "objectID": "exercises-02.html",
    "href": "exercises-02.html",
    "title": "Group work",
    "section": "",
    "text": "Let‚Äôs take 5 mins and pair up with another person. Pick out a few of the questions below to ask each other and try to answer them."
  },
  {
    "objectID": "exercises-02.html#reproducible-research",
    "href": "exercises-02.html#reproducible-research",
    "title": "Group work",
    "section": "Reproducible research",
    "text": "Reproducible research\n\nWhat is the difference between replication and reproducible?\nWhy can replication be difficult to achieve? Why is reproducibility a reasonable minimum standard when replication is not possible?\nWhat is needed to reproduce the results of a data analysis?\nWhat is literate programming?\nWhat is knitr and how is different than other literate statistical programming tools?\nWhere can you find a list of other commands that help make your code writing more efficient in RStudio?"
  },
  {
    "objectID": "tidyverse.html",
    "href": "tidyverse.html",
    "title": "3¬† Tidyverse and data viz",
    "section": "",
    "text": "library(tidyverse)"
  },
  {
    "objectID": "tidyverse.html#learning-objectives",
    "href": "tidyverse.html#learning-objectives",
    "title": "3¬† Tidyverse and data viz",
    "section": "3.1 Learning objectives",
    "text": "3.1 Learning objectives\n\nKnow difference between relative vs absolute paths\nUse modern R packages (readr) for reading and writing data in R\nUnderstand the advantages of a tibble and data.frame data objects in R\nLearn about the dplyr R package to manage data frames\nRecognize the key verbs to manage data frames in dplyr\nUse the ‚Äúpipe‚Äù operator to combine verbs together\nBe able to build up layers of graphics using ggplot()"
  },
  {
    "objectID": "tidyverse.html#reading-and-writing-data",
    "href": "tidyverse.html#reading-and-writing-data",
    "title": "3¬† Tidyverse and data viz",
    "section": "3.2 Reading and writing data",
    "text": "3.2 Reading and writing data\nHere, we introduce ays to read and write data (e.g.¬†.txt and .csv files) using base R functions as well as more modern R packages, such as readr, which is typically 10x faster than base R.\n\n3.2.1 Relative paths\nWhen you open up a .Rproj file, RStudio changes the path (location on your computer) to the .Rproj location.\nAfter opening up a .Rproj file, you can test this by\n\ngetwd()\n\nWhen you open up someone else‚Äôs R code or analysis, you might also see the\n\nsetwd()\n\nfunction being used which explicitly tells R to change the absolute path or absolute location of which directory to move into.\nFor example, say I want to clone a GitHub repo from Roger, which has 100 R script files, and in every one of those files at the top is:\n\nsetwd(\"C:\\Users\\Roger\\path\\only\\that\\Roger\\has\")\n\nThe problem is, if I want to use his code, I will need to go and hand-edit every single one of those paths (C:\\Users\\Roger\\path\\only\\that\\Roger\\has) to the path that I want to use on my computer or wherever I saved the folder on my computer (e.g.¬†/Users/Stephanie/Documents/path/only/I/have).\n\nThis is an unsustainable practice.\nI can go in and manually edit the path, but this assumes I know how to set a working directory. Not everyone does.\n\nSo instead of absolute paths:\n\nsetwd(\"/Users/jtleek/data\")\nsetwd(\"~/Desktop/files/data\")\nsetwd(\"C:\\\\Users\\\\Michelle\\\\Downloads\")\n\nA better idea is to use relative paths with the here R package.\n\nIt will recognize the top-level directory of a Git repo and supports building all paths relative to that.\nFor more on project-oriented workflow suggestions, read this post from Jenny Bryan.\n\n\n\n3.2.2 The here package\nLet‚Äôs try using the here package.\n\nlibrary(here)\n\nhere() starts at /Users/stephaniehicks/Documents/github/teaching/cshlcg2022\n\nhere::here()\n\n[1] \"/Users/stephaniehicks/Documents/github/teaching/cshlcg2022\"\n\n\nThis function creates a path unique to my computer, but will also be unique to yours.\n\nlist.files(here::here())\n\n [1] \"_book\"                  \"_freeze\"                \"_quarto.yml\"           \n [4] \"cover.png\"              \"cshlcg2022.Rproj\"       \"data\"                  \n [7] \"exercises-01.html\"      \"exercises-01.qmd\"       \"exercises-02.html\"     \n[10] \"exercises-02.qmd\"       \"exercises-03.qmd\"       \"index.html\"            \n[13] \"index.qmd\"              \"intro-to-r.html\"        \"intro-to-r.qmd\"        \n[16] \"references.bib\"         \"references.qmd\"         \"reproducible-res_files\"\n[19] \"reproducible-res.html\"  \"reproducible-res.qmd\"   \"site_libs\"             \n[22] \"tidyverse.qmd\"          \"tidyverse.rmarkdown\"   \n\nlist.files(here(\"data\"))\n\n[1] \"chicago.rds\"        \"spotify_songs.RDS\"  \"team_standings.csv\"\n\nlist.files(here(\"data\", \"team_standings.csv\"))\n\ncharacter(0)\n\n\nNow we see that using the here::here() function is a relative path (relative to the .Rproj file in our cshlcg2022 folder.\nNext, let‚Äôs use the here package to read in some data with the readr package.\n\n\n3.2.3 The readr package\nThe readr package is recently developed by posit (formerly RStudio) to deal with reading in large flat files quickly. The package provides replacements for functions like read.table() and read.csv(). The analogous functions in readr are read_table() and read_csv().\nThese functions are often much faster than their base R analogues and provide a few other nice features such as progress meters.\nFor example, the package includes a variety of functions in the read_*() family that allow you to read in data from different formats of flat files. The following table gives a guide to several functions in the read_*() family.\n\n\n\n\n\nreadr function\nUse\n\n\n\n\nread_csv()\nReads comma-separated file\n\n\nread_csv2()\nReads semicolon-separated file\n\n\nread_tsv()\nReads tab-separated file\n\n\nread_delim()\nGeneral function for reading delimited files\n\n\nread_fwf()\nReads fixed width files\n\n\nread_log()\nReads log files\n\n\n\n\n\nA typical call to read_csv() will look as follows.\n\nlibrary(readr)\nteams <- read_csv(here(\"data\", \"team_standings.csv\"))\n\nRows: 32 Columns: 2\n‚îÄ‚îÄ Column specification ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\nDelimiter: \",\"\nchr (1): Team\ndbl (1): Standing\n\n‚Ñπ Use `spec()` to retrieve the full column specification for this data.\n‚Ñπ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nteams\n\n# A tibble: 32 √ó 2\n   Standing Team       \n      <dbl> <chr>      \n 1        1 Spain      \n 2        2 Netherlands\n 3        3 Germany    \n 4        4 Uruguay    \n 5        5 Argentina  \n 6        6 Brazil     \n 7        7 Ghana      \n 8        8 Paraguay   \n 9        9 Japan      \n10       10 Chile      \n# ‚Ä¶ with 22 more rows"
  },
  {
    "objectID": "tidyverse.html#data-frames-and-tibbles",
    "href": "tidyverse.html#data-frames-and-tibbles",
    "title": "3¬† Tidyverse and data viz",
    "section": "3.3 Data frames and tibbles",
    "text": "3.3 Data frames and tibbles\nThe data frame (or data.frame) is a key data structure in statistics and in R.\nThe basic structure of a data frame is that there is one observation per row and each column represents a variable, a measure, feature, or characteristic of that observation.\nGiven the importance of managing data frames, it is important that we have good tools for dealing with them.\nFor example, operations like filtering rows, re-ordering rows, and selecting columns, can often be tedious operations in R whose syntax is not very intuitive. The dplyr package in the tidyverse is designed to mitigate a lot of these problems and to provide a highly optimized set of routines specifically for dealing with data frames.\n\n3.3.1 Tibbles\nAnother type of data structure that we need to discuss is called the tibble! It‚Äôs best to think of tibbles as an updated and stylish version of the data.frame.\nTibbles are what tidyverse packages work with most seamlessly. Now, that does not mean tidyverse packages require tibbles.\nIn fact, they still work with data.frames, but the more you work with tidyverse and tidyverse-adjacent packages, the more you will see the advantages of using tibbles.\nBefore we go any further, tibbles are data frames, but they have some new bells and whistles to make your life easier.\n\n\n3.3.2 How tibbles differ from data.frame\nThere are a number of differences between tibbles and data.frames.\nNote: To see a full vignette about tibbles and how they differ from data.frame, you will want to execute vignette(\"tibble\") and read through that vignette.\nWe will summarize some of the most important points here:\n\nInput type remains unchanged - data.frame is notorious for treating strings as factors; this will not happen with tibbles\nVariable names remain unchanged - In base R, creating data.frames will remove spaces from names, converting them to periods or add ‚Äúx‚Äù before numeric column names. Creating tibbles will not change variable (column) names.\nThere are no row.names() for a tibble - Tidy data requires that variables be stored in a consistent way, removing the need for row names.\nTibbles print first ten rows and columns that fit on one screen - Printing a tibble to screen will never print the entire huge data frame out. By default, it just shows what fits to your screen.\n\n\n\n3.3.3 as_tibble()\nSince many packages use the historical data.frame from base R, you will often find yourself in the situation that you have a data.frame and want to convert that data.frame to a tibble.\nTo do so, the as_tibble() function is exactly what you are looking for.\nFor the example, here we use a dataset (chicago.rds) containing air pollution and temperature data for the city of Chicago in the U.S.\nThe dataset is available in the /data repository. You can load the data into R using the readRDS() function.\n\nlibrary(here)\nchicago <- readRDS(here(\"data\", \"chicago.rds\"))\n\nYou can see some basic characteristics of the dataset with the dim() and str() functions.\n\ndim(chicago)\n\n[1] 6940    8\n\nstr(chicago)\n\n'data.frame':   6940 obs. of  8 variables:\n $ city      : chr  \"chic\" \"chic\" \"chic\" \"chic\" ...\n $ tmpd      : num  31.5 33 33 29 32 40 34.5 29 26.5 32.5 ...\n $ dptp      : num  31.5 29.9 27.4 28.6 28.9 ...\n $ date      : Date, format: \"1987-01-01\" \"1987-01-02\" ...\n $ pm25tmean2: num  NA NA NA NA NA NA NA NA NA NA ...\n $ pm10tmean2: num  34 NA 34.2 47 NA ...\n $ o3tmean2  : num  4.25 3.3 3.33 4.38 4.75 ...\n $ no2tmean2 : num  20 23.2 23.8 30.4 30.3 ...\n\n\nWe see this data structure is a data.frame with 6940 observations and 8 variables.\nTo convert this data.frame to a tibble you would use the following:\n\nstr(as_tibble(chicago))\n\ntibble [6,940 √ó 8] (S3: tbl_df/tbl/data.frame)\n $ city      : chr [1:6940] \"chic\" \"chic\" \"chic\" \"chic\" ...\n $ tmpd      : num [1:6940] 31.5 33 33 29 32 40 34.5 29 26.5 32.5 ...\n $ dptp      : num [1:6940] 31.5 29.9 27.4 28.6 28.9 ...\n $ date      : Date[1:6940], format: \"1987-01-01\" \"1987-01-02\" ...\n $ pm25tmean2: num [1:6940] NA NA NA NA NA NA NA NA NA NA ...\n $ pm10tmean2: num [1:6940] 34 NA 34.2 47 NA ...\n $ o3tmean2  : num [1:6940] 4.25 3.3 3.33 4.38 4.75 ...\n $ no2tmean2 : num [1:6940] 20 23.2 23.8 30.4 30.3 ..."
  },
  {
    "objectID": "tidyverse.html#the-dplyr-package",
    "href": "tidyverse.html#the-dplyr-package",
    "title": "3¬† Tidyverse and data viz",
    "section": "3.4 The dplyr package",
    "text": "3.4 The dplyr package\nThe dplyr package was developed by Posit (formely RStudio) and is an optimized and distilled version of the older plyr package for data manipulation or wrangling.\nThe dplyr package does not provide any ‚Äúnew‚Äù functionality to R per se, in the sense that everything dplyr does could already be done with base R, but it greatly simplifies existing functionality in R.\nOne important contribution of the dplyr package is that it provides a ‚Äúgrammar‚Äù (in particular, verbs) for data manipulation and for operating on data frames.\nWith this grammar, you can sensibly communicate what it is that you are doing to a data frame that other people can understand (assuming they also know the grammar). This is useful because it provides an abstraction for data manipulation that previously did not exist.\nAnother useful contribution is that the dplyr functions are very fast, as many key operations are coded in C++.\n\n3.4.1 dplyr grammar\nSome of the key ‚Äúverbs‚Äù provided by the dplyr package are\n\nselect(): return a subset of the columns of a data frame, using a flexible notation\nfilter(): extract a subset of rows from a data frame based on logical conditions\narrange(): reorder rows of a data frame\nrename(): rename variables in a data frame\nmutate(): add new variables/columns or transform existing variables\nsummarise() / summarize(): generate summary statistics of different variables in the data frame, possibly within strata\n%>%: the ‚Äúpipe‚Äù operator is used to connect multiple verb actions together into a pipeline\n\n\n\n\n\n\n\nNote\n\n\n\nThe dplyr package as a number of its own data types that it takes advantage of.\nFor example, there is a handy print() method that prevents you from printing a lot of data to the console. Most of the time, these additional data types are transparent to the user and do not need to be worried about.\n\n\n\n\n3.4.2 dplyr installation\nThe dplyr package is installed when you install and load the tidyverse meta-package.\n\nlibrary(tidyverse)\n\nYou may get some warnings when the package is loaded because there are functions in the dplyr package that have the same name as functions in other packages. For now you can ignore the warnings."
  },
  {
    "objectID": "tidyverse.html#dplyr-functions",
    "href": "tidyverse.html#dplyr-functions",
    "title": "3¬† Tidyverse and data viz",
    "section": "3.5 dplyr functions",
    "text": "3.5 dplyr functions\nAll of the functions that we will discuss here will have a few common characteristics. In particular,\n\nThe first argument is a data frame type object.\nThe subsequent arguments describe what to do with the data frame specified in the first argument, and you can refer to columns in the data frame directly (without using the $ operator, just use the column names).\nThe return result of a function is a new data frame.\nData frames must be properly formatted and annotated for this to all be useful. In particular, the data must be tidy. In short, there should be one observation per row, and each column should represent a feature or characteristic of that observation.\n\n\n3.5.1 select()\nWe will continue to use the chicago dataset containing air pollution and temperature data.\n\nchicago <- as_tibble(chicago)\nstr(chicago)\n\ntibble [6,940 √ó 8] (S3: tbl_df/tbl/data.frame)\n $ city      : chr [1:6940] \"chic\" \"chic\" \"chic\" \"chic\" ...\n $ tmpd      : num [1:6940] 31.5 33 33 29 32 40 34.5 29 26.5 32.5 ...\n $ dptp      : num [1:6940] 31.5 29.9 27.4 28.6 28.9 ...\n $ date      : Date[1:6940], format: \"1987-01-01\" \"1987-01-02\" ...\n $ pm25tmean2: num [1:6940] NA NA NA NA NA NA NA NA NA NA ...\n $ pm10tmean2: num [1:6940] 34 NA 34.2 47 NA ...\n $ o3tmean2  : num [1:6940] 4.25 3.3 3.33 4.38 4.75 ...\n $ no2tmean2 : num [1:6940] 20 23.2 23.8 30.4 30.3 ...\n\n\nThe select() function can be used to select columns of a data frame that you want to focus on.\n\n\n\n\n\n\nExample\n\n\n\nSuppose we wanted to take the first 3 columns only. There are a few ways to do this.\nWe could for example use numerical indices:\n\nnames(chicago)[1:3]\n\n[1] \"city\" \"tmpd\" \"dptp\"\n\n\nBut we can also use the names directly:\n\nsubset <- select(chicago, city:dptp)\nhead(subset)\n\n# A tibble: 6 √ó 3\n  city   tmpd  dptp\n  <chr> <dbl> <dbl>\n1 chic   31.5  31.5\n2 chic   33    29.9\n3 chic   33    27.4\n4 chic   29    28.6\n5 chic   32    28.9\n6 chic   40    35.1\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nThe : normally cannot be used with names or strings, but inside the select() function you can use it to specify a range of variable names.\nYou can also omit variables using the select() function by using the negative sign. With select() you can do\n\nselect(chicago, -(city:dptp))\n\nwhich indicates that we should include every variable except the variables city through dptp. The equivalent code in base R would be\n\ni <- match(\"city\", names(chicago))\nj <- match(\"dptp\", names(chicago))\nhead(chicago[, -(i:j)])\n\n\n\nNot super intuitive, right?\nThe select() function also allows a special syntax that allows you to specify variable names based on patterns. So, for example, if you wanted to keep every variable that ends with a ‚Äú2‚Äù, we could do\n\nsubset <- select(chicago, ends_with(\"2\"))\nstr(subset)\n\ntibble [6,940 √ó 4] (S3: tbl_df/tbl/data.frame)\n $ pm25tmean2: num [1:6940] NA NA NA NA NA NA NA NA NA NA ...\n $ pm10tmean2: num [1:6940] 34 NA 34.2 47 NA ...\n $ o3tmean2  : num [1:6940] 4.25 3.3 3.33 4.38 4.75 ...\n $ no2tmean2 : num [1:6940] 20 23.2 23.8 30.4 30.3 ...\n\n\nOr if we wanted to keep every variable that starts with a ‚Äúd‚Äù, we could do\n\nsubset <- select(chicago, starts_with(\"d\"))\nstr(subset)\n\ntibble [6,940 √ó 2] (S3: tbl_df/tbl/data.frame)\n $ dptp: num [1:6940] 31.5 29.9 27.4 28.6 28.9 ...\n $ date: Date[1:6940], format: \"1987-01-01\" \"1987-01-02\" ...\n\n\nYou can also use more general regular expressions if necessary. See the help page (?select) for more details.\n\n\n3.5.2 filter()\nThe filter() function is used to extract subsets of rows from a data frame. This function is similar to the existing subset() function in R but is quite a bit faster in my experience.\n\n\n\n\n\n\nExample\n\n\n\nSuppose we wanted to extract the rows of the chicago data frame where the levels of PM2.5 are greater than 30 (which is a reasonably high level), we could do\n\nchic.f <- filter(chicago, pm25tmean2 > 30)\nstr(chic.f)\n\ntibble [194 √ó 8] (S3: tbl_df/tbl/data.frame)\n $ city      : chr [1:194] \"chic\" \"chic\" \"chic\" \"chic\" ...\n $ tmpd      : num [1:194] 23 28 55 59 57 57 75 61 73 78 ...\n $ dptp      : num [1:194] 21.9 25.8 51.3 53.7 52 56 65.8 59 60.3 67.1 ...\n $ date      : Date[1:194], format: \"1998-01-17\" \"1998-01-23\" ...\n $ pm25tmean2: num [1:194] 38.1 34 39.4 35.4 33.3 ...\n $ pm10tmean2: num [1:194] 32.5 38.7 34 28.5 35 ...\n $ o3tmean2  : num [1:194] 3.18 1.75 10.79 14.3 20.66 ...\n $ no2tmean2 : num [1:194] 25.3 29.4 25.3 31.4 26.8 ...\n\n\nYou can see that there are now only 194 rows in the data frame and the distribution of the pm25tmean2 values is.\n\nsummary(chic.f$pm25tmean2)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  30.05   32.12   35.04   36.63   39.53   61.50 \n\n\n\n\nWe can place an arbitrarily complex logical sequence inside of filter(), so we could for example extract the rows where PM2.5 is greater than 30 and temperature is greater than 80 degrees Fahrenheit.\n\nchic.f <- filter(chicago, pm25tmean2 > 30 & tmpd > 80)\nselect(chic.f, date, tmpd, pm25tmean2)\n\n# A tibble: 17 √ó 3\n   date        tmpd pm25tmean2\n   <date>     <dbl>      <dbl>\n 1 1998-08-23    81       39.6\n 2 1998-09-06    81       31.5\n 3 2001-07-20    82       32.3\n 4 2001-08-01    84       43.7\n 5 2001-08-08    85       38.8\n 6 2001-08-09    84       38.2\n 7 2002-06-20    82       33  \n 8 2002-06-23    82       42.5\n 9 2002-07-08    81       33.1\n10 2002-07-18    82       38.8\n11 2003-06-25    82       33.9\n12 2003-07-04    84       32.9\n13 2005-06-24    86       31.9\n14 2005-06-27    82       51.5\n15 2005-06-28    85       31.2\n16 2005-07-17    84       32.7\n17 2005-08-03    84       37.9\n\n\nNow there are only 17 observations where both of those conditions are met.\nOther logical operators you should be aware of include:\n\n\n\n\n\n\n\n\nOperator\nMeaning\nExample\n\n\n\n\n==\nEquals\ncity == chic\n\n\n!=\nDoes not equal\ncity != chic\n\n\n>\nGreater than\ntmpd > 32.0\n\n\n>=\nGreater than or equal to\ntmpd >- 32.0\n\n\n<\nLess than\ntmpd < 32.0\n\n\n<=\nLess than or equal to\ntmpd <= 32.0\n\n\n%in%\nIncluded in\ncity %in% c(\"chic\", \"bmore\")\n\n\nis.na()\nIs a missing value\nis.na(pm10tmean2)\n\n\n\nNote: If you are ever unsure of how to write a logical statement, but know how to write its opposite, you can use the ! operator to negate the whole statement.\nA common use of this is to identify observations with non-missing data (e.g., !(is.na(pm10tmean2))).\n\n\n3.5.3 arrange()\nThe arrange() function is used to reorder rows of a data frame according to one of the variables/columns. Reordering rows of a data frame (while preserving corresponding order of other columns) is normally a pain to do in R. The arrange() function simplifies the process quite a bit.\nHere we can order the rows of the data frame by date, so that the first row is the earliest (oldest) observation and the last row is the latest (most recent) observation.\n\nchicago <- arrange(chicago, date)\n\nWe can now check the first few rows\n\nhead(select(chicago, date, pm25tmean2), 3)\n\n# A tibble: 3 √ó 2\n  date       pm25tmean2\n  <date>          <dbl>\n1 1987-01-01         NA\n2 1987-01-02         NA\n3 1987-01-03         NA\n\n\nand the last few rows.\n\ntail(select(chicago, date, pm25tmean2), 3)\n\n# A tibble: 3 √ó 2\n  date       pm25tmean2\n  <date>          <dbl>\n1 2005-12-29       7.45\n2 2005-12-30      15.1 \n3 2005-12-31      15   \n\n\nColumns can be arranged in descending order too by useing the special desc() operator.\n\nchicago <- arrange(chicago, desc(date))\n\nLooking at the first three and last three rows shows the dates in descending order.\n\nhead(select(chicago, date, pm25tmean2), 3)\n\n# A tibble: 3 √ó 2\n  date       pm25tmean2\n  <date>          <dbl>\n1 2005-12-31      15   \n2 2005-12-30      15.1 \n3 2005-12-29       7.45\n\ntail(select(chicago, date, pm25tmean2), 3)\n\n# A tibble: 3 √ó 2\n  date       pm25tmean2\n  <date>          <dbl>\n1 1987-01-03         NA\n2 1987-01-02         NA\n3 1987-01-01         NA\n\n\n\n\n3.5.4 rename()\nRenaming a variable in a data frame in R is surprisingly hard to do! The rename() function is designed to make this process easier.\nHere you can see the names of the first five variables in the chicago data frame.\n\nhead(chicago[, 1:5], 3)\n\n# A tibble: 3 √ó 5\n  city   tmpd  dptp date       pm25tmean2\n  <chr> <dbl> <dbl> <date>          <dbl>\n1 chic     35  30.1 2005-12-31      15   \n2 chic     36  31   2005-12-30      15.1 \n3 chic     35  29.4 2005-12-29       7.45\n\n\nThe dptp column is supposed to represent the dew point temperature and the pm25tmean2 column provides the PM2.5 data.\nHowever, these names are pretty obscure or awkward and probably be renamed to something more sensible.\n\nchicago <- rename(chicago, dewpoint = dptp, pm25 = pm25tmean2)\nhead(chicago[, 1:5], 3)\n\n# A tibble: 3 √ó 5\n  city   tmpd dewpoint date        pm25\n  <chr> <dbl>    <dbl> <date>     <dbl>\n1 chic     35     30.1 2005-12-31 15   \n2 chic     36     31   2005-12-30 15.1 \n3 chic     35     29.4 2005-12-29  7.45\n\n\nThe syntax inside the rename() function is to have the new name on the left-hand side of the = sign and the old name on the right-hand side.\n\n\n3.5.5 mutate()\nThe mutate() function exists to compute transformations of variables in a data frame. Often, you want to create new variables that are derived from existing variables and mutate() provides a clean interface for doing that.\nFor example, with air pollution data, we often want to detrend the data by subtracting the mean from the data.\n\nThat way we can look at whether a given day‚Äôs air pollution level is higher than or less than average (as opposed to looking at its absolute level).\n\nHere, we create a pm25detrend variable that subtracts the mean from the pm25 variable.\n\nchicago <- mutate(chicago, pm25detrend = pm25 - mean(pm25, na.rm = TRUE))\nhead(chicago)\n\n# A tibble: 6 √ó 9\n  city   tmpd dewpoint date        pm25 pm10tmean2 o3tmean2 no2tmean2 pm25detr‚Ä¶¬π\n  <chr> <dbl>    <dbl> <date>     <dbl>      <dbl>    <dbl>     <dbl>      <dbl>\n1 chic     35     30.1 2005-12-31 15          23.5     2.53      13.2      -1.23\n2 chic     36     31   2005-12-30 15.1        19.2     3.03      22.8      -1.17\n3 chic     35     29.4 2005-12-29  7.45       23.5     6.79      20.0      -8.78\n4 chic     37     34.5 2005-12-28 17.8        27.5     3.26      19.3       1.52\n5 chic     40     33.6 2005-12-27 23.6        27       4.47      23.5       7.33\n6 chic     35     29.6 2005-12-26  8.4         8.5    14.0       16.8      -7.83\n# ‚Ä¶ with abbreviated variable name ¬π‚Äãpm25detrend\n\n\nThere is also the related transmute() function, which does the same thing as mutate() but then drops all non-transformed variables.\nHere, we de-trend the PM10 and ozone (O3) variables.\n\nhead(transmute(chicago, \n               pm10detrend = pm10tmean2 - mean(pm10tmean2, na.rm = TRUE),\n               o3detrend = o3tmean2 - mean(o3tmean2, na.rm = TRUE)))\n\n# A tibble: 6 √ó 2\n  pm10detrend o3detrend\n        <dbl>     <dbl>\n1      -10.4     -16.9 \n2      -14.7     -16.4 \n3      -10.4     -12.6 \n4       -6.40    -16.2 \n5       -6.90    -15.0 \n6      -25.4      -5.39\n\n\nNote that there are only two columns in the transmuted data frame.\n\n\n3.5.6 group_by()\nThe group_by() function is used to generate summary statistics from the data frame within strata defined by a variable.\nFor example, in this air pollution dataset, you might want to know what the average annual level of PM2.5 is?\nSo the stratum is the year, and that is something we can derive from the date variable.\nIn conjunction with the group_by() function, we often use the summarize() function (or summarise() for some parts of the world).\nNote: The general operation here is a combination of\n\nSplitting a data frame into separate pieces defined by a variable or group of variables (group_by())\nThen, applying a summary function across those subsets (summarize())\n\n\n\n\n\n\n\nExample\n\n\n\nFirst, we can create a year variable using as.POSIXlt().\n\nchicago <- mutate(chicago, year = as.POSIXlt(date)$year + 1900)\n\nNow we can create a separate data frame that splits the original data frame by year.\n\nyears <- group_by(chicago, year)\n\nFinally, we compute summary statistics for each year in the data frame with the summarize() function.\n\nsummarize(years, \n          pm25 = mean(pm25, na.rm = TRUE), \n          o3 = max(o3tmean2, na.rm = TRUE), \n          no2 = median(no2tmean2, na.rm = TRUE))\n\n# A tibble: 19 √ó 4\n    year  pm25    o3   no2\n   <dbl> <dbl> <dbl> <dbl>\n 1  1987 NaN    63.0  23.5\n 2  1988 NaN    61.7  24.5\n 3  1989 NaN    59.7  26.1\n 4  1990 NaN    52.2  22.6\n 5  1991 NaN    63.1  21.4\n 6  1992 NaN    50.8  24.8\n 7  1993 NaN    44.3  25.8\n 8  1994 NaN    52.2  28.5\n 9  1995 NaN    66.6  27.3\n10  1996 NaN    58.4  26.4\n11  1997 NaN    56.5  25.5\n12  1998  18.3  50.7  24.6\n13  1999  18.5  57.5  24.7\n14  2000  16.9  55.8  23.5\n15  2001  16.9  51.8  25.1\n16  2002  15.3  54.9  22.7\n17  2003  15.2  56.2  24.6\n18  2004  14.6  44.5  23.4\n19  2005  16.2  58.8  22.6\n\n\nsummarize() returns a data frame with year as the first column, and then the annual summary statistics of pm25, o3, and no2.\n\n\n\n\n3.5.7 %>%\nThe pipeline operator %>% is very handy for stringing together multiple dplyr functions in a sequence of operations.\nNotice above that every time we wanted to apply more than one function, the sequence gets buried in a sequence of nested function calls that is difficult to read, i.e.\n\nthird(second(first(x)))\n\nThis nesting is not a natural way to think about a sequence of operations.\nThe %>% operator allows you to string operations in a left-to-right fashion, i.e.\n\nfirst(x) %>% second %>% third\n\n\n\n\n\n\n\nExample\n\n\n\nTake the example that we just did in the last section, but here use the pipe operator in a single expression.\n\nmutate(chicago, year = as.POSIXlt(date)$year + 1900) %>%    \n        group_by(year) %>% \n        summarize(years, pm25 = mean(pm25, na.rm = TRUE), \n          o3 = max(o3tmean2, na.rm = TRUE), \n          no2 = median(no2tmean2, na.rm = TRUE))\n\n`summarise()` has grouped output by 'year'. You can override using the\n`.groups` argument.\n\n\n# A tibble: 131,860 √ó 12\n# Groups:   year [19]\n    year city   tmpd dewpoint date        pm25 pm10tme‚Ä¶¬π o3tme‚Ä¶¬≤ no2tm‚Ä¶¬≥ pm25d‚Ä¶‚Å¥\n   <dbl> <chr> <dbl>    <dbl> <date>     <dbl>     <dbl>   <dbl>   <dbl>   <dbl>\n 1  2005 chic     35     30.1 2005-12-31  16.2      23.5    2.53    13.2   -1.23\n 2  2005 chic     36     31   2005-12-30  16.2      19.2    3.03    22.8   -1.17\n 3  2005 chic     35     29.4 2005-12-29  16.2      23.5    6.79    20.0   -8.78\n 4  2005 chic     37     34.5 2005-12-28  16.2      27.5    3.26    19.3    1.52\n 5  2005 chic     40     33.6 2005-12-27  16.2      27      4.47    23.5    7.33\n 6  2005 chic     35     29.6 2005-12-26  16.2       8.5   14.0     16.8   -7.83\n 7  2005 chic     35     32.1 2005-12-25  16.2       8     14.4     13.8   -9.53\n 8  2005 chic     37     35.2 2005-12-24  16.2      25.2    1.77    32.0   14.5 \n 9  2005 chic     41     32.6 2005-12-23  16.2      34.5    6.91    29.1   16.7 \n10  2005 chic     22     23.3 2005-12-22  16.2      42.5    5.39    33.7   20.4 \n# ‚Ä¶ with 131,850 more rows, 2 more variables: o3 <dbl>, no2 <dbl>, and\n#   abbreviated variable names ¬π‚Äãpm10tmean2, ¬≤‚Äão3tmean2, ¬≥‚Äãno2tmean2, ‚Å¥‚Äãpm25detrend\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\nIn the above code, I pass the chicago data frame to the first call to mutate(), but then afterwards I do not have to pass the first argument to group_by() or summarize().\n\nOnce you travel down the pipeline with %>%, the first argument is taken to be the output of the previous element in the pipeline.\n\n\n\n\n\n3.5.8 slice_*()\nThe slice_sample() function of the dplyr package will allow you to see a sample of random rows in random order.\nThe number of rows to show is specified by the n argument.\n\nThis can be useful if you do not want to print the entire tibble, but you want to get a greater sense of the values.\nThis is a good option for data analysis reports, where printing the entire tibble would not be appropriate if the tibble is quite large.\n\n\n\n\n\n\n\nExample\n\n\n\n\nslice_sample(chicago, n = 10)\n\n# A tibble: 10 √ó 10\n   city   tmpd dewpoint date        pm25 pm10tme‚Ä¶¬π o3tme‚Ä¶¬≤ no2tm‚Ä¶¬≥ pm25d‚Ä¶‚Å¥  year\n   <chr> <dbl>    <dbl> <date>     <dbl>     <dbl>   <dbl>   <dbl>   <dbl> <dbl>\n 1 chic   68       57.9 1998-09-03  19.3      42     25.6     31.7    3.07  1998\n 2 chic   24       20.6 1996-02-15  NA        22.2    9.96    30.7   NA     1996\n 3 chic   39       36.1 1997-10-28  NA        30.5    6.02    27.8   NA     1997\n 4 chic   38       29.3 1999-11-16  NA        16.5   12.0     23.3   NA     1999\n 5 chic   39       34.2 2004-12-08  13.9      27      7.51    22.0   -2.29  2004\n 6 chic   66       46.3 1999-09-23  NA        44.5   24.9     26.6   NA     1999\n 7 chic   33.5     26.6 1995-02-02  NA        16.4   17.4     23.7   NA     1995\n 8 chic   74       60.6 2003-09-11  37.8      58.5   39.2     26.9   21.6   2003\n 9 chic   54       44.4 2005-05-11  NA        17     26.6     12.0   NA     2005\n10 chic   82       67.4 2002-06-20  33        80.5   47.4     30.8   16.8   2002\n# ‚Ä¶ with abbreviated variable names ¬π‚Äãpm10tmean2, ¬≤‚Äão3tmean2, ¬≥‚Äãno2tmean2,\n#   ‚Å¥‚Äãpm25detrend\n\n\n\n\nYou can also use slice_head() or slice_tail() to take a look at the top rows or bottom rows of your tibble. Again the number of rows can be specified with the n argument.\nThis will show the first 5 rows.\n\nslice_head(chicago, n = 5)\n\n# A tibble: 5 √ó 10\n  city   tmpd dewpoint date        pm25 pm10tmean2 o3tme‚Ä¶¬π no2tm‚Ä¶¬≤ pm25d‚Ä¶¬≥  year\n  <chr> <dbl>    <dbl> <date>     <dbl>      <dbl>   <dbl>   <dbl>   <dbl> <dbl>\n1 chic     35     30.1 2005-12-31 15          23.5    2.53    13.2   -1.23  2005\n2 chic     36     31   2005-12-30 15.1        19.2    3.03    22.8   -1.17  2005\n3 chic     35     29.4 2005-12-29  7.45       23.5    6.79    20.0   -8.78  2005\n4 chic     37     34.5 2005-12-28 17.8        27.5    3.26    19.3    1.52  2005\n5 chic     40     33.6 2005-12-27 23.6        27      4.47    23.5    7.33  2005\n# ‚Ä¶ with abbreviated variable names ¬π‚Äão3tmean2, ¬≤‚Äãno2tmean2, ¬≥‚Äãpm25detrend\n\n\nThis will show the last 5 rows.\n\nslice_tail(chicago, n = 5)\n\n# A tibble: 5 √ó 10\n  city   tmpd dewpoint date        pm25 pm10tmean2 o3tme‚Ä¶¬π no2tm‚Ä¶¬≤ pm25d‚Ä¶¬≥  year\n  <chr> <dbl>    <dbl> <date>     <dbl>      <dbl>   <dbl>   <dbl>   <dbl> <dbl>\n1 chic   32       28.9 1987-01-05    NA       NA      4.75    30.3      NA  1987\n2 chic   29       28.6 1987-01-04    NA       47      4.38    30.4      NA  1987\n3 chic   33       27.4 1987-01-03    NA       34.2    3.33    23.8      NA  1987\n4 chic   33       29.9 1987-01-02    NA       NA      3.30    23.2      NA  1987\n5 chic   31.5     31.5 1987-01-01    NA       34      4.25    20.0      NA  1987\n# ‚Ä¶ with abbreviated variable names ¬π‚Äão3tmean2, ¬≤‚Äãno2tmean2, ¬≥‚Äãpm25detrend"
  },
  {
    "objectID": "tidyverse.html#the-ggplot2-plotting-system",
    "href": "tidyverse.html#the-ggplot2-plotting-system",
    "title": "3¬† Tidyverse and data viz",
    "section": "3.6 The ggplot2 Plotting System",
    "text": "3.6 The ggplot2 Plotting System\nIn this section, we will get into a little more of the nitty gritty of how ggplot2 builds plots and how you can customize various aspects of any plot.\n\n3.6.1 Basic components of a ggplot2 plot\nA ggplot2 plot consists of a number of key components.\n\nA data frame: stores all of the data that will be displayed on the plot\naesthetic mappings: describe how data are mapped to color, size, shape, location\ngeoms: geometric objects like points, lines, shapes\nfacets: describes how conditional/panel plots should be constructed\nstats: statistical transformations like binning, quantiles, smoothing\nscales: what scale an aesthetic map uses (example: left-handed = red, right-handed = blue)\ncoordinate system: describes the system in which the locations of the geoms will be drawn\n\nIt is essential to organize your data into a data frame before you start with ggplot2 (and all the appropriate metadata so that your data frame is self-describing and your plots will be self-documenting).\nWhen building plots in ggplot2 (rather than using qplot()), the ‚Äúartist‚Äôs palette‚Äù model may be the closest analogy.\nEssentially, you start with some raw data, and then you gradually add bits and pieces to it to create a plot.\n\n\n\n\n\n\nNote\n\n\n\nPlots are built up in layers, with the typically ordering being\n\nPlot the data\nOverlay a summary\nAdd metadata and annotation\n\nFor quick exploratory plots you may not get past step 1."
  },
  {
    "objectID": "tidyverse.html#building-up-in-layers",
    "href": "tidyverse.html#building-up-in-layers",
    "title": "3¬† Tidyverse and data viz",
    "section": "3.7 Building up in layers",
    "text": "3.7 Building up in layers\nFirst, we can create a ggplot object that stores the dataset and the basic aesthetics for mapping the x- and y-coordinates for the plot.\n\n3.7.1 palmerpenguins dataset\nHere we will use the palmerpenguins dataset. These data contain observations for 344 penguins. There are 3 different species of penguins in this dataset, collected from 3 islands in the Palmer Archipelago, Antarctica.\n\n\n\n\n\nPalmer penguins\n\n\n\n\n[Source: Artwork by Allison Horst]\n\nlibrary(palmerpenguins)\n\n\nglimpse(penguins)\n\nRows: 344\nColumns: 8\n$ species           <fct> Adelie, Adelie, Adelie, Adelie, Adelie, Adelie, Adel‚Ä¶\n$ island            <fct> Torgersen, Torgersen, Torgersen, Torgersen, Torgerse‚Ä¶\n$ bill_length_mm    <dbl> 39.1, 39.5, 40.3, NA, 36.7, 39.3, 38.9, 39.2, 34.1, ‚Ä¶\n$ bill_depth_mm     <dbl> 18.7, 17.4, 18.0, NA, 19.3, 20.6, 17.8, 19.6, 18.1, ‚Ä¶\n$ flipper_length_mm <int> 181, 186, 195, NA, 193, 190, 181, 195, 193, 190, 186‚Ä¶\n$ body_mass_g       <int> 3750, 3800, 3250, NA, 3450, 3650, 3625, 4675, 3475, ‚Ä¶\n$ sex               <fct> male, female, female, NA, female, male, female, male‚Ä¶\n$ year              <int> 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007, 2007‚Ä¶\n\n\nIf we wanted to count the number of penguins for each of the three species, we can use the count() function in dplyr:\n\npenguins %>% \n  count(species)\n\n# A tibble: 3 √ó 2\n  species       n\n  <fct>     <int>\n1 Adelie      152\n2 Chinstrap    68\n3 Gentoo      124\n\n\nFor example, we see there are a total of 152 Adelie penguins in the palmerpenguins dataset.\n\ng <- ggplot(penguins, aes(x = flipper_length_mm, \n                          y = bill_length_mm))\nsummary(g)\n\ndata: species, island, bill_length_mm, bill_depth_mm,\n  flipper_length_mm, body_mass_g, sex, year [344x8]\nmapping:  x = ~flipper_length_mm, y = ~bill_length_mm\nfaceting: <ggproto object: Class FacetNull, Facet, gg>\n    compute_layout: function\n    draw_back: function\n    draw_front: function\n    draw_labels: function\n    draw_panels: function\n    finish_data: function\n    init_scales: function\n    map_data: function\n    params: list\n    setup_data: function\n    setup_params: function\n    shrink: TRUE\n    train_scales: function\n    vars: function\n    super:  <ggproto object: Class FacetNull, Facet, gg>\n\nclass(g)\n\n[1] \"gg\"     \"ggplot\"\n\n\nYou can see above that the object g contains the dataset penguins and the mappings.\nNow, normally if you were to print() a ggplot object a plot would appear on the plot device, however, our object g actually does not contain enough information to make a plot yet.\n\ng <- penguins %>% \n      ggplot(aes(x = flipper_length_mm, \n                 y = bill_length_mm))\nprint(g)\n\n\n\n\nNothing to see here!\n\n\n\n\n\n\n3.7.2 First plot with point layer\nTo make a scatter plot, we need add at least one geom, such as points.\nHere, we add the geom_point() function to create a traditional scatter plot.\n\ng <- penguins %>% \n      ggplot(aes(x = flipper_length_mm, \n                 y = bill_length_mm))\ng + geom_point()\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nHow does ggplot know what points to plot? In this case, it can grab them from the data frame penguins that served as the input into the ggplot() function.\n\n\n3.7.3 Adding more layers\n\n3.7.3.1 smooth\nBecause the data appear rather noisy, it might be better if we added a smoother on top of the points to see if there is a trend in the data with PM2.5.\n\ng + \n  geom_point() + \n  geom_smooth()\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nScatterplot with smoother\n\n\n\n\nThe default smoother is a loess smoother, which is flexible and nonparametric but might be too flexible for our purposes. Perhaps we‚Äôd prefer a simple linear regression line to highlight any first order trends. We can do this by specifying method = \"lm\" to geom_smooth().\n\ng + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nHere, we can see there appears to be a increasing trend.\nWe can color the points by species and a smoother by adding a linear regression.\n\npenguins %>% \n  ggplot(aes(x = flipper_length_mm, \n             y = bill_length_mm, \n             color = species)) + \n  geom_point() + \n  geom_smooth(method = \"lm\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n3.7.3.2 facets\nWe can also stratify the scatter plot by another variable (e.g.¬†sex) by adding a facet_grid() or facet_wrap() function.\n\npenguins %>% \n  filter(!is.na(sex)) %>% \n  ggplot(aes(x = flipper_length_mm, \n             y = bill_length_mm, \n             color = species)) + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  facet_grid(.~sex)\n\n\n\n\n\n\n3.7.3.3 Changing the theme\nThe default theme for ggplot2 uses the gray background with white grid lines.\nIf you don‚Äôt find this suitable, you can use the black and white theme by using the theme_bw() function.\nThe theme_bw() function also allows you to set the typeface for the plot, in case you don‚Äôt want the default Helvetica. Here we change the typeface to Times.\nFor things that only make sense globally, use theme(), i.e.¬†theme(legend.position = \"none\"). Two standard appearance themes are included\n\ntheme_gray(): The default theme (gray background)\ntheme_bw(): More stark/plain\n\n\ng + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  theme_bw(base_family = \"Times\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\n\n\n3.7.3.4 Modifying labels\nThere are a variety of annotations you can add to a plot, including different kinds of labels.\n\nxlab() for x-axis labels\nylab() for y-axis labels\nggtitle() for specifying plot titles\n\nlabs() function is generic and can be used to modify multiple types of labels at once\n:::\nHere is an example of modifying the title and the x and y labels to make the plot a bit more informative.\n\ng + \n  geom_point() + \n  geom_smooth(method = \"lm\") + \n  labs(title = \"Palmer penguins\", \n       x = \"flipper length\", \n       y = \"bill length\")\n\nWarning: Removed 2 rows containing non-finite values (`stat_smooth()`).\n\n\nWarning: Removed 2 rows containing missing values (`geom_point()`).\n\n\n\n\n\nModifying plot labels"
  },
  {
    "objectID": "tidyverse.html#session-info",
    "href": "tidyverse.html#session-info",
    "title": "3¬† Tidyverse and data viz",
    "section": "3.8 Session Info",
    "text": "3.8 Session Info\n\nsessionInfo()\n\nR version 4.2.2 (2022-10-31)\nPlatform: aarch64-apple-darwin21.6.0 (64-bit)\nRunning under: macOS Ventura 13.0.1\n\nMatrix products: default\nBLAS:   /opt/homebrew/Cellar/openblas/0.3.21/lib/libopenblasp-r0.3.21.dylib\nLAPACK: /opt/homebrew/Cellar/r/4.2.2/lib/R/lib/libRlapack.dylib\n\nlocale:\n[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] palmerpenguins_0.1.1 here_1.0.1           forcats_0.5.2       \n [4] stringr_1.4.1        dplyr_1.0.10         purrr_0.3.5         \n [7] readr_2.1.3          tidyr_1.2.1          tibble_3.1.8        \n[10] ggplot2_3.4.0        tidyverse_1.3.2     \n\nloaded via a namespace (and not attached):\n [1] lattice_0.20-45     lubridate_1.9.0     assertthat_0.2.1   \n [4] rprojroot_2.0.3     digest_0.6.30       utf8_1.2.2         \n [7] R6_2.5.1            cellranger_1.1.0    backports_1.4.1    \n[10] reprex_2.0.2        evaluate_0.18       httr_1.4.4         \n[13] highr_0.9           pillar_1.8.1        rlang_1.0.6        \n[16] googlesheets4_1.0.1 readxl_1.4.1        rstudioapi_0.14    \n[19] Matrix_1.5-3        rmarkdown_2.18      splines_4.2.2      \n[22] labeling_0.4.2      googledrive_2.0.0   htmlwidgets_1.5.4  \n[25] bit_4.0.5           munsell_0.5.0       broom_1.0.1        \n[28] compiler_4.2.2      modelr_0.1.10       xfun_0.35          \n[31] pkgconfig_2.0.3     mgcv_1.8-41         htmltools_0.5.3    \n[34] tidyselect_1.2.0    fansi_1.0.3         crayon_1.5.2       \n[37] tzdb_0.3.0          dbplyr_2.2.1        withr_2.5.0        \n[40] grid_4.2.2          nlme_3.1-160        jsonlite_1.8.3     \n[43] gtable_0.3.1        lifecycle_1.0.3     DBI_1.1.3          \n[46] magrittr_2.0.3      scales_1.2.1        cli_3.4.1          \n[49] stringi_1.7.8       vroom_1.6.0         farver_2.1.1       \n[52] fs_1.5.2            xml2_1.3.3          ellipsis_0.3.2     \n[55] generics_0.1.3      vctrs_0.5.1         tools_4.2.2        \n[58] bit64_4.0.5         glue_1.6.2          hms_1.1.2          \n[61] parallel_4.2.2      fastmap_1.1.0       yaml_2.3.6         \n[64] timechange_0.1.1    colorspace_2.0-3    gargle_1.2.1       \n[67] rvest_1.0.3         knitr_1.41          haven_2.5.1"
  },
  {
    "objectID": "exercises-03.html",
    "href": "exercises-03.html",
    "title": "Workshop",
    "section": "",
    "text": "In this workshop, you will explore spotify songs!\nPlease write up your solution using R Markdown and knitr. Please show all your code for each of the answers to each part.\nAt the end of the workshop, we will go over the answers."
  },
  {
    "objectID": "exercises-03.html#data",
    "href": "exercises-03.html#data",
    "title": "Workshop",
    "section": "Data",
    "text": "Data\nThat data for this part of the assignment comes from TidyTuesday, which is a weekly podcast and global community activity brought to you by the R4DS Online Learning Community. The goal of TidyTuesday is to help R learners learn in real-world contexts.\n\n\n\n\n\nIcon from TidyTuesday\n\n\n\n\n[Source: TidyTuesday]\nTo access the data, you need to install the tidytuesdayR R package and use the function tt_load() with the date of ‚Äò2020-01-21‚Äô to load the data.\n\ninstall.packages(\"tidytuesdayR\")\n\nThis is how you can download the data.\n\ntuesdata <- tidytuesdayR::tt_load('2020-01-21')\nspotify_songs <- tuesdata$spotify_songs\n\nHowever, if you use this code, you will hit an API limit after trying to compile the document a few times. Instead, I suggest you use the following code below. Here, I provide the code below for you to avoid re-downloading data:\n\nlibrary(here)\nlibrary(tidyverse)\n\n# tests if a directory named \"data\" exists locally\nif(!dir.exists(here(\"data\"))) { dir.create(here(\"data\")) }\n\n# saves data only once (not each time you knit a R Markdown)\nif(!file.exists(here(\"data\",\"spotify_songs.RDS\"))) {\n  url_csv <- 'https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-01-21/spotify_songs.csv'\n  spotify_songs <- readr::read_csv(url_csv)\n  \n  # save the file to RDS objects\n  saveRDS(spotify_songs, file= here(\"data\",\"spotify_songs.RDS\"))\n}\n\nHere we read in the .RDS dataset locally from our computing environment:\n\nspotify_songs <- readRDS(here(\"data\",\"spotify_songs.RDS\"))\nas_tibble(spotify_songs)\n\n# A tibble: 32,833 √ó 23\n   track_id      track‚Ä¶¬π track‚Ä¶¬≤ track‚Ä¶¬≥ track‚Ä¶‚Å¥ track‚Ä¶‚Åµ track‚Ä¶‚Å∂ playl‚Ä¶‚Å∑ playl‚Ä¶‚Å∏\n   <chr>         <chr>   <chr>     <dbl> <chr>   <chr>   <chr>   <chr>   <chr>  \n 1 6f807x0ima9a‚Ä¶ I Don'‚Ä¶ Ed She‚Ä¶      66 2oCs0D‚Ä¶ I Don'‚Ä¶ 2019-0‚Ä¶ Pop Re‚Ä¶ 37i9dQ‚Ä¶\n 2 0r7CVbZTWZgb‚Ä¶ Memori‚Ä¶ Maroon‚Ä¶      67 63rPSO‚Ä¶ Memori‚Ä¶ 2019-1‚Ä¶ Pop Re‚Ä¶ 37i9dQ‚Ä¶\n 3 1z1Hg7Vb0AhH‚Ä¶ All th‚Ä¶ Zara L‚Ä¶      70 1HoSmj‚Ä¶ All th‚Ä¶ 2019-0‚Ä¶ Pop Re‚Ä¶ 37i9dQ‚Ä¶\n 4 75FpbthrwQmz‚Ä¶ Call Y‚Ä¶ The Ch‚Ä¶      60 1nqYsO‚Ä¶ Call Y‚Ä¶ 2019-0‚Ä¶ Pop Re‚Ä¶ 37i9dQ‚Ä¶\n 5 1e8PAfcKUYoK‚Ä¶ Someon‚Ä¶ Lewis ‚Ä¶      69 7m7vv9‚Ä¶ Someon‚Ä¶ 2019-0‚Ä¶ Pop Re‚Ä¶ 37i9dQ‚Ä¶\n 6 7fvUMiyapMsR‚Ä¶ Beauti‚Ä¶ Ed She‚Ä¶      67 2yiy9c‚Ä¶ Beauti‚Ä¶ 2019-0‚Ä¶ Pop Re‚Ä¶ 37i9dQ‚Ä¶\n 7 2OAylPUDDfwR‚Ä¶ Never ‚Ä¶ Katy P‚Ä¶      62 7INHYS‚Ä¶ Never ‚Ä¶ 2019-0‚Ä¶ Pop Re‚Ä¶ 37i9dQ‚Ä¶\n 8 6b1RNvAcJjQH‚Ä¶ Post M‚Ä¶ Sam Fe‚Ä¶      69 6703SR‚Ä¶ Post M‚Ä¶ 2019-0‚Ä¶ Pop Re‚Ä¶ 37i9dQ‚Ä¶\n 9 7bF6tCO3gFb8‚Ä¶ Tough ‚Ä¶ Avicii       68 7CvAfG‚Ä¶ Tough ‚Ä¶ 2019-0‚Ä¶ Pop Re‚Ä¶ 37i9dQ‚Ä¶\n10 1IXGILkPm0tO‚Ä¶ If I C‚Ä¶ Shawn ‚Ä¶      67 4Qxzbf‚Ä¶ If I C‚Ä¶ 2019-0‚Ä¶ Pop Re‚Ä¶ 37i9dQ‚Ä¶\n# ‚Ä¶ with 32,823 more rows, 14 more variables: playlist_genre <chr>,\n#   playlist_subgenre <chr>, danceability <dbl>, energy <dbl>, key <dbl>,\n#   loudness <dbl>, mode <dbl>, speechiness <dbl>, acousticness <dbl>,\n#   instrumentalness <dbl>, liveness <dbl>, valence <dbl>, tempo <dbl>,\n#   duration_ms <dbl>, and abbreviated variable names ¬π‚Äãtrack_name,\n#   ¬≤‚Äãtrack_artist, ¬≥‚Äãtrack_popularity, ‚Å¥‚Äãtrack_album_id, ‚Åµ‚Äãtrack_album_name,\n#   ‚Å∂‚Äãtrack_album_release_date, ‚Å∑‚Äãplaylist_name, ‚Å∏‚Äãplaylist_id\n\n\nWe can take a glimpse at the data\n\nglimpse(spotify_songs)\n\nRows: 32,833\nColumns: 23\n$ track_id                 <chr> \"6f807x0ima9a1j3VPbc7VN\", \"0r7CVbZTWZgbTCYdfa‚Ä¶\n$ track_name               <chr> \"I Don't Care (with Justin Bieber) - Loud Lux‚Ä¶\n$ track_artist             <chr> \"Ed Sheeran\", \"Maroon 5\", \"Zara Larsson\", \"Th‚Ä¶\n$ track_popularity         <dbl> 66, 67, 70, 60, 69, 67, 62, 69, 68, 67, 58, 6‚Ä¶\n$ track_album_id           <chr> \"2oCs0DGTsRO98Gh5ZSl2Cx\", \"63rPSO264uRjW1X5E6‚Ä¶\n$ track_album_name         <chr> \"I Don't Care (with Justin Bieber) [Loud Luxu‚Ä¶\n$ track_album_release_date <chr> \"2019-06-14\", \"2019-12-13\", \"2019-07-05\", \"20‚Ä¶\n$ playlist_name            <chr> \"Pop Remix\", \"Pop Remix\", \"Pop Remix\", \"Pop R‚Ä¶\n$ playlist_id              <chr> \"37i9dQZF1DXcZDD7cfEKhW\", \"37i9dQZF1DXcZDD7cf‚Ä¶\n$ playlist_genre           <chr> \"pop\", \"pop\", \"pop\", \"pop\", \"pop\", \"pop\", \"po‚Ä¶\n$ playlist_subgenre        <chr> \"dance pop\", \"dance pop\", \"dance pop\", \"dance‚Ä¶\n$ danceability             <dbl> 0.748, 0.726, 0.675, 0.718, 0.650, 0.675, 0.4‚Ä¶\n$ energy                   <dbl> 0.916, 0.815, 0.931, 0.930, 0.833, 0.919, 0.8‚Ä¶\n$ key                      <dbl> 6, 11, 1, 7, 1, 8, 5, 4, 8, 2, 6, 8, 1, 5, 5,‚Ä¶\n$ loudness                 <dbl> -2.634, -4.969, -3.432, -3.778, -4.672, -5.38‚Ä¶\n$ mode                     <dbl> 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, ‚Ä¶\n$ speechiness              <dbl> 0.0583, 0.0373, 0.0742, 0.1020, 0.0359, 0.127‚Ä¶\n$ acousticness             <dbl> 0.10200, 0.07240, 0.07940, 0.02870, 0.08030, ‚Ä¶\n$ instrumentalness         <dbl> 0.00e+00, 4.21e-03, 2.33e-05, 9.43e-06, 0.00e‚Ä¶\n$ liveness                 <dbl> 0.0653, 0.3570, 0.1100, 0.2040, 0.0833, 0.143‚Ä¶\n$ valence                  <dbl> 0.518, 0.693, 0.613, 0.277, 0.725, 0.585, 0.1‚Ä¶\n$ tempo                    <dbl> 122.036, 99.972, 124.008, 121.956, 123.976, 1‚Ä¶\n$ duration_ms              <dbl> 194754, 162600, 176616, 169093, 189052, 16304‚Ä¶\n\n\nFor all of the questions below, you can ignore the missing values in the dataset, so e.g.¬†when taking averages, just remove the missing values before taking the average, if needed."
  },
  {
    "objectID": "exercises-03.html#tasks",
    "href": "exercises-03.html#tasks",
    "title": "Workshop",
    "section": "Tasks",
    "text": "Tasks\nUse functions from dplyr and ggplot2 to answer the following questions.\n\nHow many songs are in each genre?\n\n\n# Add your solution here\n\n\nWhat is average value of energy and acousticness in the latin genre in this dataset?\n\n\n# Add your solution here\n\n\nCalculate the average duration of song (in minutes) across all subgenres. Which subgenre has the longest song on average?\n\n\n# Add your solution here\n\n\nMake two boxplots side-by-side of the danceability of songs stratifying by whether a song has a fast or slow tempo. Define fast tempo as any song that has a tempo above its median value. On average, which songs are more danceable?\n\nHint: You may find the case_when() function useful in this part, which can be used to map values from one variable to different values in a new variable (when used in a mutate() call).\n\n## Generate some random numbers\ndat <- tibble(x = rnorm(100))\nslice(dat, 1:3)\n\n# A tibble: 3 √ó 1\n       x\n   <dbl>\n1 -2.09 \n2  3.24 \n3 -0.910\n\n## Create a new column that indicates whether the value of 'x' is positive or negative\ndat %>%\n        mutate(is_positive = case_when(\n                x >= 0 ~ \"Yes\",\n                x < 0 ~ \"No\"\n        ))\n\n# A tibble: 100 √ó 2\n        x is_positive\n    <dbl> <chr>      \n 1 -2.09  No         \n 2  3.24  Yes        \n 3 -0.910 No         \n 4 -0.335 No         \n 5  0.933 Yes        \n 6  0.935 Yes        \n 7  0.161 Yes        \n 8 -0.875 No         \n 9  0.498 Yes        \n10  1.86  Yes        \n# ‚Ä¶ with 90 more rows\n\n\n\n# Add your solution here"
  }
]